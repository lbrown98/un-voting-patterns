{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bb0680",
   "metadata": {},
   "source": [
    "# United Nations Voting Patterns\n",
    "#### [CMSC320 Final Tutorial]\n",
    "Authors: Lauren Brown, Angel Lin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3157a-becc-4e0d-8a43-1568da875d0f",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "* get rid of requests we don't use\n",
    "* annotate the code to explain what we're doing and why [tutorial!]\n",
    "* have to explain what broad categories we wanted to analyze and why\n",
    "    * clean up our doc about what categories we want to use and add it to the github, explain why we are only using certain [un] categories for now (most bang for our buck)\n",
    "    \n",
    "* say that we want to do a frequency analysis of which countries abstain/are not present the most so that we can figure out if there are patterns to certain countries at all\n",
    "* also say that we want to include abstaintions/absences in our error analysis but didn't get to it\n",
    "* add background readings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffbd974",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "### **United Nations Overview**\n",
    "\n",
    "The United Nations (UN) is an international organization founded after World War II. The purpose of the UN is to maintain international peace and security, provide humanitarian assistance to those in need, protect human rights, and uphold international laws. It pursues these goals through several bodies, including:\n",
    "* the General Assembly, the main policy-making body which includes one seat for each recognized member-state. Many committees and sub-committees help to form and inform policies, within their specific jurisdictions, that may be considered by the GA; \n",
    "* several councils (Security Council, Economic and Social Council, and Trusteeship Council) which are responsible for international peace and security, economic, social, and environmental challenges, and trust territories, respectively. These bodies each have their own membership processes but membership or decisions are often biased towards the preferences of the P5: China, France, Russia, France,  the United Kingdom, and the United States;\n",
    "* the International Court of Justice (ICJ) which settles international legal disputes between countries and gives advice to the UN when requested; and \n",
    "* the Secretariat, which consist of staff from all over the world and carry out the day to day operations of the UN.\n",
    "\n",
    "#### **Background Readings**\n",
    "For more information regarding:\n",
    "* the founding and history of the United Nations: [click here](https://www.history.com/topics/world-war-ii/united-nations).\n",
    "* the structure of the United Nations, [click here](https://guides.lib.fsu.edu/c.php?g=946756&p=6852483).\n",
    "\n",
    "### **Motivation**\n",
    "\n",
    "This tutorial looks at how countries in the United Nations vote with respect to other countries. We ask the question, as countries rise and fall, how do UN voting patterns shift, if at all? How do voting blocks form and dissapate over time? If we can discover which countries are the center of voting blocks, we can determine which countries will be able to most able to influence the outcomes of UN resolutions. \n",
    "\n",
    "In this project, we use an unsupervised machine learning algorithm, k-means clustering, to determine how similiarly countries vote compared to each other and to visualize the how voting blocks have formed and changed over time. We hypothesize that as countries rise and fall from power, clusters will form and dissolve around these countries. The null hypothesis, then, is that there is no relationship between any voting blocks that may form and the rise and fall of countries.\n",
    "\n",
    "Specifically, the countries we are interested in for this dataset are the United States, the Soviet Union, and China. These three countries have been major world players since the founding of the United Nations, and while we will be looking for the center of voting blocks regardless of who it may be, these three countries will be highlighted throughout our data exploration and analysis. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In the General Assembly, different resolutions may be voting or non-voting resolutions. This project concentrates on voting data in the General Assembly. For any given voting resolution, a country may vote Yay, Nay, Abstain, or not be present and thus not vote. While the meaning Yay and Nay are fairly straitforward, the reasons behind abstentions or absenses are less so. Countries usually abstain for political reasons; for example, one may abstain from a resolution rebuking a nation because while they recognize a wrongdoing, that nation is an ally. They may also abstain from a resolution that may otherwise force them to choose between an ally and strong trading partner. A country may not be present for a vote for a variety of reasons, from the representative being unwell to intentionally protesting against the vote. There is no real way to generalize the reasons for these two responses, which will come into play later in our dataset.\n",
    "\n",
    "Finally, over time countries rise and fall, and appropriately join or leave the United Nations. This will show up in our dataset later as missing data for certain resolutions for which the country did not exist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6fb947-3448-4582-8075-9514d871c110",
   "metadata": {},
   "source": [
    "### **Required Libraries and Tools**\n",
    "\n",
    "This project utilizes the Python3 languages and packages to collect, explore, visualize, and analyze the data. To reproduce the code, please ensure you have the following packages installed; you can install any of these by using the command <code>$ pip3 install [package] </code> in your terminal or command prompt. \n",
    "\n",
    "* <code>reqests</code>: allows us to retrieve website data using Python [(docs)](https://docs.python-requests.org/en/latest/)\n",
    "* <code>BeautifulSoup</code>: allows us to parse and scrape HTML after retrieving website data [(docs)](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "* <code>numpy</code>: supports a wide range of operations. Required for Pandas installation [(docs)](https://numpy.org/)\n",
    "* <code>pandas</code>: used for data manipulation and analysis [(docs)](https://pandas.pydata.org/)\n",
    "* <code>time</code>: allows us to create delays in code operations [(docs)](https://docs.python.org/3/library/time.html)\n",
    "* <code>datetime</code>: used for parsing date strings into objects [(docs)](https://docs.python.org/3/library/datetime.html)\n",
    "* <code>matplotlib</code>: includes an extrordinary amount of data visualization functions [(docs)](https://matplotlib.org/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717d1d6d-d43c-4fc3-a3c6-1cb7ad1980ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8af61b",
   "metadata": {},
   "source": [
    "### **Data Collection** \n",
    "\n",
    "\n",
    "* collected categories of resolutions\n",
    "* decided which to focus on/had relations --> development & human rights\n",
    "* sorted them manually\n",
    "* scraped resolution links and then voting data using requests, beautiful soup, etc\n",
    "* needed to use rate limiter because of unconfirmed scraping permissions\n",
    "* needed to save data collected to file incase anything was lost during long scraping session due to rate limiter (took approx. 3 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff6755-13cf-4fe3-a739-e9e2878a589e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "category_links_df = pd.read_csv('category-links.csv')\n",
    "\n",
    "visited_categories = pd.read_csv('visited_cats.csv')['visited categories'].tolist()\n",
    "resolution_urls = pd.read_csv('res_urls.csv')['res_urls'].tolist()\n",
    "total_resolutions = 0\n",
    "\n",
    "category_links_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00ed82f4-298a-4860-aced-23a159ca6c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_res_links_from_page(page_link):\n",
    "    \n",
    "    links = []\n",
    "    \n",
    "    page = requests.get(page_link)\n",
    "    if page.status_code != 200:\n",
    "        raise Exception(\"Something went wrong loading category: \" + category + \", error code: \" + page.status_code)\n",
    "\n",
    "    html = page.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    resolution_cnt = int(soup.find(\"strong\", {\"class\": None}).text)\n",
    "\n",
    "    if resolution_cnt > 50:\n",
    "        if resolution_cnt%50 == 0:\n",
    "            page_count = (int) (resolution_cnt/50)\n",
    "        else: page_count = int((resolution_cnt/50) + 1)\n",
    "    else: page_count = 1\n",
    "    \n",
    "    for page in range(page_count):\n",
    "\n",
    "        for div in soup.find_all(\"div\", {\"class\": \"moreinfo\"}):\n",
    "            res_link_suffix = div.find(\"a\")[\"href\"]\n",
    "            links.append('https://digitallibrary.un.org' + res_link_suffix)\n",
    "        \n",
    "        time.sleep(5)\n",
    "\n",
    "        #load the next page if you're not already on the last page (0 indexing)\n",
    "        if (page+1 != page_count):\n",
    "            next_page_link_suffix = soup.find(\"span\", {\"class\": \"rec-navigation\"}).findAll(\"a\")[-1][\"href\"]\n",
    "            next_page_link = 'https://digitallibrary.un.org' + next_page_link_suffix\n",
    "\n",
    "            page = requests.get(next_page_link)\n",
    "            if page.status_code != 200:\n",
    "                raise Exception(\"Something went wrong loading next page, error code: \" + page.status_code)\n",
    "\n",
    "            html = page.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "        \n",
    "    if (resolution_cnt != len(links)):\n",
    "        raise Exception(\"resolution count does not match\")\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff75b4b-df2c-46e2-99f0-329b00b6f545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Make resolution_urls unique\n",
    "def unique(list1):\n",
    "    # initialize a null list\n",
    "    unique_list = []\n",
    "     \n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4fcd568-effa-4678-b05a-b04c711c8a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get the initial website with the categories\n",
    "for cat, link in zip (category_links_df[\"un category\"], category_links_df[\"link\"]):\n",
    "    if cat not in visited_categories:\n",
    "        try:\n",
    "            cat_res_links = get_res_links_from_page(link) #grab the links, may throw an exception\n",
    "            resolution_urls = resolution_urls + cat_res_links #append the new links list to the bigger old links list\n",
    "            visited_categories.append(cat)\n",
    "        except :\n",
    "            print(\"oh no the UN blocked you maybe :(\")\n",
    "        finally:\n",
    "            time.sleep(5) #delay to hopefully prevent the un from detecting and blocking us\n",
    "\n",
    "unq_res_urls = unique(resolution_urls)\n",
    "res_urls_df = pd.DataFrame(unq_res_urls, columns = ['res_urls'])\n",
    "res_urls_df.to_csv('res_urls.csv', index=False)\n",
    "visited_cats = pd.DataFrame(visited_categories, columns = ['visited categories'])\n",
    "visited_cats.to_csv('visited_cats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed536e1a-d28c-4924-a9d8-2ab86e77610c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for all voting data df, index column is the country and each following column is the resolution id. \n",
    "# cell is each country's vote (Y if yes, N if no, A if abstain, NP if not present, or NaN if the country didn't exist to vote at the time\n",
    "all_voting_data = pd.read_csv('all_voting_data.csv')\n",
    "\n",
    "## rows are resolution id's, columns are names of resolutions and years they were voted on\n",
    "all_res_data = pd.read_csv('all_res_data.csv')\n",
    "\n",
    "resolution_urls = pd.read_csv('res_urls.csv')['res_urls'].tolist()\n",
    "visited_res_urls = pd.read_csv('visited_res_urls.csv')['visited_res_urls'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092c5ef",
   "metadata": {},
   "source": [
    "### **Data Processing**  \n",
    "\n",
    "* stored data in 2 data frames\n",
    "* explain 2 df setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad9eddd6-ec75-4380-874b-1096b17792a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_resolution(res_url):\n",
    "    res_page = requests.get(res_url)\n",
    "    if res_page.status_code != 200:\n",
    "        raise Exception(\"Something went wrong loading resolution, error code: \" + res_page.status_code)\n",
    "    \n",
    "    html = res_page.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    metadata = soup.find(\"div\", {\"id\" : \"details-collapse\"})\n",
    "\n",
    "    #checking to make sure the vote was recorded\n",
    "    # we only care about recorded votes since they allow us to track how countries change their views over time\n",
    "    row_content_meta = metadata.find_all(\"span\", {\"class\" : \"value col-xs-12 col-sm-9 col-md-10\"})\n",
    "    recorded_vote = [False if 'NON-RECORDED' in row.get_text() else True for row in row_content_meta]\n",
    "\n",
    "    if False not in recorded_vote:\n",
    "\n",
    "        rows = metadata.find_all(\"div\", {\"class\" : \"metadata-row\"})\n",
    "\n",
    "        title = \"\"\n",
    "        res_id = \"\"\n",
    "        date = \"\"\n",
    "        vote_table = \"\"\n",
    "\n",
    "        for row in rows:\n",
    "            row_title = row.find(\"span\", {\"class\" : \"title col-xs-12 col-sm-3 col-md-2\"}).text\n",
    "            row_value = row.find(\"span\", {\"class\" : \"value col-xs-12 col-sm-9 col-md-10\"})\n",
    "\n",
    "            #strip newline chars from the string\n",
    "            row_title = row_title.strip()\n",
    "\n",
    "            #get the information we want from the html\n",
    "            if row_title == 'Title':\n",
    "                title = row_value.text\n",
    "            elif row_title == 'Resolution':\n",
    "                res_id = row_value.text\n",
    "            elif row_title == 'Vote date':\n",
    "                date = row_value.text\n",
    "                dt = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "            elif row_title == 'Vote':\n",
    "                vote_table = row_value\n",
    "\n",
    "        # some resolutions don't have the full date but the year exists elsewhere on the page, so extract that in those instances\n",
    "        if date == \"\":\n",
    "            year = soup.find(\"div\", {\"class\" : \"one-row-metadata value\"}).text.strip()\n",
    "            dt = datetime.strptime(year, \"%Y\")\n",
    "            \n",
    "        #get resolution metadata minus voting data, append it as a row to the df of all resolution metadata     \n",
    "        res_data = pd.DataFrame({'Resolution ID': [res_id],\n",
    "                        'Resolution Name' : [title],\n",
    "                        'Year' : [dt.year]})  \n",
    "\n",
    "        #get vote information into a dataframe \n",
    "        vts = str(vote_table)\n",
    "\n",
    "        for i in range(len(vts)):\n",
    "            if vts[i] in ['Y', 'N', 'A']:\n",
    "                vts = vts[:i]+'<br/> ' + vts[i:]\n",
    "                break\n",
    "            elif vts[i:i+2] == '> ': #if the first country in the list was absent and didn't vote, string should look like this\n",
    "                vts = vts[:i]+'<br/> ' + vts[i:]\n",
    "                break\n",
    "        \n",
    "        vts = vts.replace(\"<br>\", \"<br/>\")\n",
    "\n",
    "        #vts is a string but to parse it using beautifulsoup we want it as soup\n",
    "        vote_table = BeautifulSoup(vts, 'html.parser') \n",
    "        #print(str(vote_table))\n",
    "        \n",
    "        res_voting_data = pd.DataFrame(columns = ['country', res_id])\n",
    "        \n",
    "        for br in vote_table.findAll('br'):\n",
    "            next_s = br.nextSibling\n",
    "            \n",
    "            if next_s[0:2].strip() in ['Y', 'N', 'A']:\n",
    "                vote = next_s[0:2].strip()\n",
    "                country = next_s[3:].strip()\n",
    "            else:\n",
    "                vote = 'NP'\n",
    "                country = next_s.strip()\n",
    "\n",
    "            res_voting_data.loc[len(res_voting_data.index)] = [country, vote] \n",
    "\n",
    "        return (res_data, res_voting_data)\n",
    "    return (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91104853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get vote data from each resolution\n",
    "\n",
    "#resolution df (x= resolution index, y = name, year)\n",
    "#country_votes df (row = country, col= resolution index) row,col = vote\n",
    "try:\n",
    "    for res_url in resolution_urls:\n",
    "        # print(res_url)\n",
    "        try:\n",
    "            if res_url not in visited_res_urls:\n",
    "                res_data, res_voting_data = process_resolution(res_url)\n",
    "                #print(res_data)\n",
    "                #print(res_voting_data)\n",
    "\n",
    "                #once you have the data for the resolution, add it to the larger dfs of all the data (voting and otherwise) \n",
    "                #for all resolutions\n",
    "                if (res_data, res_voting_data) is not (None, None):\n",
    "                    \n",
    "                    #add as a row to the end of the df\n",
    "                    all_res_data = pd.concat([all_res_data, res_data], ignore_index = True, axis = 0)\n",
    "                    \n",
    "                    #add as a column -> outer merge to make sure countries join correctly\n",
    "                    all_voting_data = all_voting_data.merge(res_voting_data, how='outer', on='country') \n",
    "\n",
    "                visited_res_urls.append(res_url)\n",
    "                time.sleep(5) \n",
    "        except:\n",
    "            print(\"error somewhere\")\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # save everything\n",
    "    all_res_data.to_csv('all_res_data.csv', index=False)\n",
    "    all_voting_data.to_csv('all_voting_data.csv', index=False)\n",
    "    \n",
    "    visited_res_url_df = pd.DataFrame(visited_res_urls, columns = ['visited_res_urls'])\n",
    "    visited_res_url_df.to_csv('visited_res_urls.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52f87a",
   "metadata": {},
   "source": [
    "### **Data Visualization/Representation**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2e3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "473b3cee",
   "metadata": {},
   "source": [
    "### **Exploratory Data Analysis**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10155e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c81e44e",
   "metadata": {},
   "source": [
    "### **Hypothesis Testing**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eceaefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "820e27e6",
   "metadata": {},
   "source": [
    "### **Communication of insights attained**  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
