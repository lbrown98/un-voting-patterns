{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bb0680",
   "metadata": {},
   "source": [
    "# United Nations Voting Patterns\n",
    "#### [CMSC320 Final Tutorial]\n",
    "Authors: Lauren Brown, Angel Lin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3157a-becc-4e0d-8a43-1568da875d0f",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "* get rid of requests we don't use and add requests from the k means clustering and other analysis stuff\n",
    "* add NaN for all countries not present "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffbd974",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "### **United Nations Overview**\n",
    "\n",
    "The United Nations (UN) is an international organization founded after World War II. The purpose of the UN is to maintain international peace and security, provide humanitarian assistance to those in need, protect human rights, and uphold international laws. It pursues these goals through several bodies, including:\n",
    "* the General Assembly, the main policy-making body which includes one seat for each recognized member-state. Many committees and sub-committees help to form and inform policies, within their specific jurisdictions, that may be considered by the GA; \n",
    "* several councils (Security Council, Economic and Social Council, and Trusteeship Council) which are responsible for international peace and security, economic, social, and environmental challenges, and trust territories, respectively. These bodies each have their own membership processes but membership or decisions are often biased towards the preferences of the P5: China, France, Russia, France,  the United Kingdom, and the United States;\n",
    "* the International Court of Justice (ICJ) which settles international legal disputes between countries and gives advice to the UN when requested; and \n",
    "* the Secretariat, which consist of staff from all over the world and carry out the day to day operations of the UN.\n",
    "\n",
    "#### **Background Readings**\n",
    "For more information regarding:\n",
    "* the founding and history of the United Nations: [click here](https://www.history.com/topics/world-war-ii/united-nations).\n",
    "* the structure of the United Nations, [click here](https://guides.lib.fsu.edu/c.php?g=946756&p=6852483).\n",
    "\n",
    "### **Motivation**\n",
    "\n",
    "This tutorial looks at how countries in the United Nations vote with respect to other countries. We ask the question, as countries rise and fall, how do UN voting patterns shift, if at all? How do voting blocks form and dissapate over time? If we can discover which countries are the center of voting blocks, we can determine which countries will be able to most able to influence the outcomes of UN resolutions. \n",
    "\n",
    "In this project, we use an unsupervised machine learning algorithm, k-means clustering, to determine how similiarly countries vote compared to each other and to visualize the how voting blocks have formed and changed over time. We hypothesize that as countries rise and fall from power, clusters will form and dissolve around these countries. The null hypothesis, then, is that there is no relationship between any voting blocks that may form and the rise and fall of countries.\n",
    "\n",
    "Specifically, the countries we are interested in for this dataset are the United States, the Soviet Union, and China. These three countries have been major world players since the founding of the United Nations, and while we will be looking for the center of voting blocks regardless of who it may be, these three countries will be highlighted throughout our data exploration and analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6fb947-3448-4582-8075-9514d871c110",
   "metadata": {},
   "source": [
    "### **Required Libraries and Tools**\n",
    "\n",
    "This project utilizes the Python3 languages and packages to collect, explore, visualize, and analyze the data. To reproduce the code, please ensure you have the following packages installed; you can install any of these by using the command <code>$ pip3 install [package] </code> in your terminal or command prompt. \n",
    "\n",
    "* <code>reqests</code>: allows us to retrieve website data using Python [(docs)](https://docs.python-requests.org/en/latest/)\n",
    "* <code>BeautifulSoup</code>: allows us to parse and scrape HTML after retrieving website data [(docs)](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "* <code>numpy</code>: supports a wide range of operations. Required for Pandas installation [(docs)](https://numpy.org/)\n",
    "* <code>pandas</code>: used for data manipulation and analysis [(docs)](https://pandas.pydata.org/)\n",
    "* <code>time</code>: allows us to create delays in code operations [(docs)](https://docs.python.org/3/library/time.html)\n",
    "* <code>datetime</code>: used for parsing date strings into objects [(docs)](https://docs.python.org/3/library/datetime.html)\n",
    "* <code>matplotlib</code>: includes an extrordinary amount of data visualization functions [(docs)](https://matplotlib.org/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717d1d6d-d43c-4fc3-a3c6-1cb7ad1980ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bac8ad-fc87-4e27-8b20-2e2f0603e4fc",
   "metadata": {},
   "source": [
    "## **Data Collection and Processing** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d34ed3-2e1b-4d1d-b795-7a5ad3314e56",
   "metadata": {},
   "source": [
    "### **UN Subjects** \n",
    "\n",
    "The United Nations keeps all their resolution data on their [digital library website](https://digitallibrary.un.org/), in which anyone can search through any resolution, speech, or any other document from the UN. After filtering to just [General Assembly voting data](https://digitallibrary.un.org/search?ln=en&cc=Voting%20Data&p=&f=&rm=&ln=en&sf=&so=d&rg=50&c=Voting%20Data&c=&of=hb&fti=0&fct__2=General%20Assembly&fti=0&fct__2=General%20Assembly&fct__9=Vote), there are almost 7000 resolutions from 1946 to 20222. \n",
    "\n",
    "Since there is no API provided by the UN to easily access or filter all of the resolution data, we had to resort to scraping necessary data of each resolution's webpage. Scraping is the process of using a bot to extract content and data from a website, so that we don't have to do it manually for each resolution. To determine which resolutions we wanted to use for our dataset, we decided to utilize the UN's ability to filter by different subjects to access certain resolutions. There are hundreds of subjects to filter by, some of which are contained within broader subjects. \n",
    "\n",
    "We saw no way to get around manually filtering through the subjects, and we placed each subject into the following broader categories of our own design: \n",
    "* International Peacekeeping/Security, and Weapons Agreements: Includes any resolutions about wars and conflicts (civil, between countries, etc), weapons agreements (nuclear, chemical, IAEA notes), security agreements, cybersecurity, post-war international judicial courts (ICJ/ICTY/ICTR), terrorism, Hostage-taking during wars, and more.\n",
    "* Internal UN functioning: Includes budgets and resolutions discussing the functioning of the UN as a whole\n",
    "* Economic: Includes any international economic treaties, economic rights of countries, and global trade\n",
    "* Development: Includes human issues that the development status of a country might affect (like health), resolutions directly related to a country's development (infrastructure, development towards a specific country, etc.), and decolonization \n",
    "* Sustainability/environment: Includes any resolutions that may be related to climate change or how the environment has affected humans\n",
    "* Human Rights/Humanitarian: Includes humanitarian assistance, disaster relief, human rights questions, etc. \n",
    "\n",
    "When determining which categories to use, we decided to not use international peacekeeping/security and weapons agreements, or internal functioning resolutions, because at the time we believed that there would not be enough disparity between countries in these resolutions, and that the inclusion of these resolutions may neutralize the other data we collected.[<sup>*</sup>](#fn1) We also were interested in development and human rights resolutions, and chose to include the other categories since they all either were directly related to this or were so influential to these topics that they could not be separated from them. \n",
    "\n",
    "After deciding on which categories to use, we still had over a hundred subjects to include in our dataset. As a final way of filtering, we chose subjects from each category that included the most number of resolutions and represented somewhat of a spread over our categories; this way, we could get the maximum \"bang for our buck\". \n",
    "\n",
    "\n",
    "<span id=\"fn1\"><sup>*</sup></span>We have since found this to be somewhat of an error, since not only does our data visualization program account for these types of similarities but also many countries may disagree on country-specific resolutions related to international security. We discuss a bit more about this in our final notes at the very end of the project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81efeecf-87d7-4c47-b173-c05c985e0ea4",
   "metadata": {},
   "source": [
    "### **Resolution Links** \n",
    "\n",
    "Code-wise, the first thing we needed to do was get a link to each resolution. We had already created csv files beforehand to store the links, so we simply read in each csv. While performing all our scraping, it was important to save all the data as we did it in case our program crashed or cut off, especially since our scraping permissions were unconfirmed by the UN. By always saving the resolution urls we scraped and ensuring that we also kept track of which subjects we visited, we ensured that we would never have to visit a website more than once and no data would be lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eff6755-13cf-4fe3-a739-e9e2878a589e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>un category</th>\n",
       "      <th>number of resolutions</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HUMAN RIGHTS ADVANCEMENT</td>\n",
       "      <td>223</td>\n",
       "      <td>https://digitallibrary.un.org/search?ln=en&amp;cc=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNRWA--ACTIVITIES</td>\n",
       "      <td>191</td>\n",
       "      <td>https://digitallibrary.un.org/search?ln=en&amp;cc=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DECOLONIZATION</td>\n",
       "      <td>121</td>\n",
       "      <td>https://digitallibrary.un.org/search?ln=en&amp;cc=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HUMAN RIGHTS--REPORTS</td>\n",
       "      <td>99</td>\n",
       "      <td>https://digitallibrary.un.org/search?ln=en&amp;cc=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APARTHEID</td>\n",
       "      <td>87</td>\n",
       "      <td>https://digitallibrary.un.org/search?ln=en&amp;cc=...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                un category  number of resolutions  \\\n",
       "0  HUMAN RIGHTS ADVANCEMENT                    223   \n",
       "1         UNRWA--ACTIVITIES                    191   \n",
       "2            DECOLONIZATION                    121   \n",
       "3     HUMAN RIGHTS--REPORTS                     99   \n",
       "4                 APARTHEID                     87   \n",
       "\n",
       "                                                link  \n",
       "0  https://digitallibrary.un.org/search?ln=en&cc=...  \n",
       "1  https://digitallibrary.un.org/search?ln=en&cc=...  \n",
       "2  https://digitallibrary.un.org/search?ln=en&cc=...  \n",
       "3  https://digitallibrary.un.org/search?ln=en&cc=...  \n",
       "4  https://digitallibrary.un.org/search?ln=en&cc=...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_links_df = pd.read_csv('category-links.csv')\n",
    "\n",
    "visited_categories = pd.read_csv('visited_cats.csv')['visited categories'].tolist()\n",
    "resolution_urls = pd.read_csv('res_urls.csv')['res_urls'].tolist()\n",
    "\n",
    "category_links_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56498e3-2e34-4e45-b208-8a128a63a50c",
   "metadata": {},
   "source": [
    "The following code is a function that we repeat for each subject; it retrieves the website data for each subject link and adds each the link to resolution in the subject to a list. That list is then returned at the end of the function. If there are more than 50 resolutions in the subject, the subject may have more than one page to go through, and the function accounts for that as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ed82f4-298a-4860-aced-23a159ca6c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_res_links_from_page(page_link):\n",
    "    \n",
    "    links = []\n",
    "    \n",
    "    page = requests.get(page_link)\n",
    "    if page.status_code != 200:\n",
    "        raise Exception(\"Something went wrong loading category: \" + category + \", error code: \" + page.status_code)\n",
    "\n",
    "    html = page.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    resolution_cnt = int(soup.find(\"strong\", {\"class\": None}).text)\n",
    "\n",
    "    if resolution_cnt > 50:\n",
    "        if resolution_cnt%50 == 0:\n",
    "            page_count = (int) (resolution_cnt/50)\n",
    "        else: page_count = int((resolution_cnt/50) + 1)\n",
    "    else: page_count = 1\n",
    "    \n",
    "    for page in range(page_count):\n",
    "\n",
    "        for div in soup.find_all(\"div\", {\"class\": \"moreinfo\"}):\n",
    "            res_link_suffix = div.find(\"a\")[\"href\"]\n",
    "            links.append('https://digitallibrary.un.org' + res_link_suffix)\n",
    "        \n",
    "        time.sleep(5)\n",
    "\n",
    "        #load the next page if you're not already on the last page (0 indexing)\n",
    "        if (page+1 != page_count):\n",
    "            next_page_link_suffix = soup.find(\"span\", {\"class\": \"rec-navigation\"}).findAll(\"a\")[-1][\"href\"]\n",
    "            next_page_link = 'https://digitallibrary.un.org' + next_page_link_suffix\n",
    "\n",
    "            page = requests.get(next_page_link)\n",
    "            if page.status_code != 200:\n",
    "                raise Exception(\"Something went wrong loading next page, error code: \" + page.status_code)\n",
    "\n",
    "            html = page.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "        \n",
    "    if (resolution_cnt != len(links)):\n",
    "        raise Exception(\"resolution count does not match\")\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a492eda0-4307-4f94-aa87-16ee385ec0a2",
   "metadata": {},
   "source": [
    "This function is used later to ensure all the resolution links in our final list are unique, i.e. there were no overlaps of resolutions between subjects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff75b4b-df2c-46e2-99f0-329b00b6f545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Make resolution_urls unique\n",
    "def unique(res_list):\n",
    "    # initialize a null list\n",
    "    unique_list = []\n",
    "     \n",
    "    # traverse for all elements\n",
    "    for x in res_list:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70787228-4190-416d-acb1-afd4ed763fce",
   "metadata": {},
   "source": [
    "Here, we take every subject and subject link and run it through the <code>get_res_links_from_page</code> function defined above if the subject has not already been processed. To reiterate, what we get back is a list of individual resolution links, and this is appended to a longer list of resolution links from all subjects. Due to the unconfirmed permissions issue, we used a rate limiter (i.e. added time between each run of the function) to prevent the UN website from detecting our bot. Finally, the <code>unique</code> function defined above is called to ensure no two resolutions are repeated, and both the list of resolution URLs and list of visited categories is stored into a csv for permanent storage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4fcd568-effa-4678-b05a-b04c711c8a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get the initial website with the categories\n",
    "for cat, link in zip (category_links_df[\"un category\"], category_links_df[\"link\"]):\n",
    "    if cat not in visited_categories:\n",
    "        try:\n",
    "            cat_res_links = get_res_links_from_page(link) #grab the links, may throw an exception\n",
    "            resolution_urls = resolution_urls + cat_res_links #append the new links list to the bigger old links list\n",
    "            visited_categories.append(cat)\n",
    "        except :\n",
    "            print(\"oh no the UN blocked you maybe :(\")\n",
    "        finally:\n",
    "            time.sleep(5) #delay to hopefully prevent the un from detecting and blocking us\n",
    "\n",
    "unq_res_urls = unique(resolution_urls)\n",
    "res_urls_df = pd.DataFrame(unq_res_urls, columns = ['res_urls'])\n",
    "res_urls_df.to_csv('res_urls.csv', index=False)\n",
    "visited_cats = pd.DataFrame(visited_categories, columns = ['visited categories'])\n",
    "visited_cats.to_csv('visited_cats.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888a367-958c-40e3-9bc2-52a0843f06c2",
   "metadata": {},
   "source": [
    "### **Data Storage** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f15af-1377-4abb-8cfc-e686cd263752",
   "metadata": {},
   "source": [
    "We decided to use two dataframes to hold the data we needed. The first dataframe stored voting data for each country and resolution, with each row on the table representing each country that existed from the founding of the UN to modern day, and each column representing a resolution (stored as a resolution ID - a unique ID that the UN gives to each resolution). Each individual entry in this table is a country's vote for a specific resolution. The second dataframe stored extra information about each resolution that would be helpful to us when visualizing and analyzing our data; each row in this dataframe was a resolution ID, and the other two columns were the name and year of the resolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe86cc2d-fc1e-41e4-8d21-9a5b8bf064f7",
   "metadata": {},
   "source": [
    "Again, we had already created csv files beforehand to store the data, so we simply read in each csv. We sometimes ran this code separately from the resolution link code, so we included a line that read in the csv of the resolution urls that we had already gathered, and also read in a list of visited resolution urls that worked the same way as the visited subjects list in the previous code section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed536e1a-d28c-4924-a9d8-2ab86e77610c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for all voting data df, index column / each row is a country and each following column is each resolution id. \n",
    "# cell is each country's vote (Y if yes, N if no, A if abstain, NP if not present, or NaN if the country didn't exist to vote at the time\n",
    "all_voting_data = pd.read_csv('all_voting_data.csv')\n",
    "\n",
    "## rows are resolution id's, columns are names of resolutions and years they were voted on\n",
    "all_res_data = pd.read_csv('all_res_data.csv')\n",
    "\n",
    "resolution_urls = pd.read_csv('res_urls.csv')['res_urls'].tolist()\n",
    "visited_res_urls = pd.read_csv('visited_res_urls.csv')['visited_res_urls'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186439b3-2df9-4f7c-9181-3019391575cc",
   "metadata": {},
   "source": [
    "For each resolution, after accessing the website data, we needed to figure out if the vote was recorded or not; we did not include non-recorded votes in our project since they can not tell us how countries voted with respect to each other for that given resolution. If a vote was non-recorded, then the function does not collect any data and produces a result that indicates the resolution was not recorded. Otherwise, the code collects the resolution id, title, year, and vote data, and puts them into two dataframes that are essentially smaller versions of the larger resolution and voting information dataframes. The result of the code for a recorded vote is a tuple, or a list of two things, that includes the two mini resolution data and voting dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2836aac8-8a00-4f6f-b5b8-82e79258ec7c",
   "metadata": {},
   "source": [
    "Additionally, in the General Assembly, different resolutions may be voting or non-voting resolutions. For any given voting resolution, a country may vote Yay, Nay, Abstain, or not be present and thus not vote. While the meaning Yay and Nay are fairly straitforward, the reasons behind abstentions or absenses are less so. Countries usually abstain for political reasons; for example, one may abstain from a resolution rebuking a nation because while they recognize a wrongdoing, that nation is an ally. They may also abstain from a resolution that may otherwise force them to choose between an ally and strong trading partner. A country may not be present for a vote for a variety of reasons, from the representative being unwell to intentionally protesting against the vote. There is no real way to generalize the reasons for these two responses, which will come into play later during our data analysis. \n",
    "\n",
    "On each resolution page: Yay is coded as Y; Nay is coded as N; Abstain is coded as A; and not present is indicated with a lack of a vote next to the country's name. To indicate that a country was not present in our dataframe, we code the lack of vote as NP for \"not present.\"\n",
    "\n",
    "Finally, over time countries rise and fall, and appropriately join or leave the United Nations. In our larger dataset that we compile later, if the country did not exist at the time of the vote, we code this as NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9eddd6-ec75-4380-874b-1096b17792a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_resolution(res_url):\n",
    "    res_page = requests.get(res_url)\n",
    "    if res_page.status_code != 200:\n",
    "        raise Exception(\"Something went wrong loading resolution, error code: \" + res_page.status_code)\n",
    "    \n",
    "    html = res_page.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    metadata = soup.find(\"div\", {\"id\" : \"details-collapse\"})\n",
    "\n",
    "    #checking to make sure the vote was recorded\n",
    "    # we only care about recorded votes since they allow us to track how countries change their views over time\n",
    "    row_content_meta = metadata.find_all(\"span\", {\"class\" : \"value col-xs-12 col-sm-9 col-md-10\"})\n",
    "    recorded_vote = [False if 'NON-RECORDED' in row.get_text() else True for row in row_content_meta]\n",
    "\n",
    "    if False not in recorded_vote:\n",
    "\n",
    "        rows = metadata.find_all(\"div\", {\"class\" : \"metadata-row\"})\n",
    "\n",
    "        title = \"\"\n",
    "        res_id = \"\"\n",
    "        date = \"\"\n",
    "        vote_table = \"\"\n",
    "\n",
    "        for row in rows:\n",
    "            row_title = row.find(\"span\", {\"class\" : \"title col-xs-12 col-sm-3 col-md-2\"}).text\n",
    "            row_value = row.find(\"span\", {\"class\" : \"value col-xs-12 col-sm-9 col-md-10\"})\n",
    "\n",
    "            #strip newline chars from the string\n",
    "            row_title = row_title.strip()\n",
    "\n",
    "            #get the information we want from the html\n",
    "            if row_title == 'Title':\n",
    "                title = row_value.text\n",
    "            elif row_title == 'Resolution':\n",
    "                res_id = row_value.text\n",
    "            elif row_title == 'Vote date':\n",
    "                date = row_value.text\n",
    "                dt = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "            elif row_title == 'Vote':\n",
    "                vote_table = row_value\n",
    "\n",
    "        # some resolutions don't have the full date but the year exists elsewhere on the page, so extract that in those instances\n",
    "        if date == \"\":\n",
    "            year = soup.find(\"div\", {\"class\" : \"one-row-metadata value\"}).text.strip()\n",
    "            dt = datetime.strptime(year, \"%Y\")\n",
    "            \n",
    "        #get resolution metadata minus voting data, append it as a row to the df of all resolution metadata     \n",
    "        res_data = pd.DataFrame({'Resolution ID': [res_id],\n",
    "                        'Resolution Name' : [title],\n",
    "                        'Year' : [dt.year]})  \n",
    "\n",
    "        #get vote information into a dataframe \n",
    "        vts = str(vote_table)\n",
    "\n",
    "        for i in range(len(vts)):\n",
    "            if vts[i] in ['Y', 'N', 'A']:\n",
    "                vts = vts[:i]+'<br/> ' + vts[i:]\n",
    "                break\n",
    "            elif vts[i:i+2] == '> ': #if the first country in the list was absent and didn't vote, string should look like this\n",
    "                vts = vts[:i]+'<br/> ' + vts[i:]\n",
    "                break\n",
    "        \n",
    "        vts = vts.replace(\"<br>\", \"<br/>\")\n",
    "\n",
    "        #vts is a string but to parse it using beautifulsoup we want it as soup\n",
    "        vote_table = BeautifulSoup(vts, 'html.parser') \n",
    "        #print(str(vote_table))\n",
    "        \n",
    "        res_voting_data = pd.DataFrame(columns = ['country', res_id])\n",
    "        \n",
    "        for br in vote_table.findAll('br'):\n",
    "            next_s = br.nextSibling\n",
    "            \n",
    "            if next_s[0:2].strip() in ['Y', 'N', 'A']:\n",
    "                vote = next_s[0:2].strip()\n",
    "                country = next_s[3:].strip()\n",
    "            else:\n",
    "                vote = 'NP'\n",
    "                country = next_s.strip()\n",
    "\n",
    "            res_voting_data.loc[len(res_voting_data.index)] = [country, vote] \n",
    "\n",
    "        return (res_data, res_voting_data)\n",
    "    return (0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734d3d1-f90e-489f-982b-64b113c49946",
   "metadata": {},
   "source": [
    "For each resolution, if it is not already listed in the visited resolution urls list (and thus already been processed), we run the <code>process_resolution</code> function defined above and save the output as mini resolution and voting dataframes. We then check to see if the output indicates that the resolution was non-recorded; if it wasn't we concatenate the mini dataframes to the end of the longer dataframes using merge for the resolution data, which has the same columns, and an outer join for voting data, which allow us to append countries that didn't exist prior to the pre-existing list and not exclude voting data for countries that did not exist at the time of the vote. It also uses a rate limiter to prevent bot detection on the UN website. Finally, it saves all data that is collected in any given scraping session back into a csv so we don't lose any of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91104853",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:9: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/tmp/ipykernel_51/3515635216.py:9: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if (res_data, res_voting_data) is not (None, None):\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for res_url in resolution_urls:\n",
    "        try:\n",
    "            if res_url not in visited_res_urls:\n",
    "                res_data, res_voting_data = process_resolution(res_url)\n",
    "\n",
    "                #once you have the data for the resolution, add it to the larger dfs of all the data \n",
    "                #(voting and otherwise) for all resolutions\n",
    "                if (res_data, res_voting_data) is not (None, None):\n",
    "                    \n",
    "                    #add as a row to the end of the df\n",
    "                    all_res_data = pd.concat([all_res_data, res_data], ignore_index = True, axis = 0)\n",
    "                    \n",
    "                    #add as a column -> outer merge to make sure countries join correctly\n",
    "                    all_voting_data = all_voting_data.merge(res_voting_data, how='outer', on='country') \n",
    "\n",
    "                visited_res_urls.append(res_url)\n",
    "                time.sleep(5) \n",
    "        except:\n",
    "            print(\"error\")\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # save everything\n",
    "    all_res_data.to_csv('all_res_data.csv', index=False)\n",
    "    all_voting_data.to_csv('all_voting_data.csv', index=False)\n",
    "    \n",
    "    visited_res_url_df = pd.DataFrame(visited_res_urls, columns = ['visited_res_urls'])\n",
    "    visited_res_url_df.to_csv('visited_res_urls.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52f87a",
   "metadata": {},
   "source": [
    "### **Data Visualization/Representation**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2e3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "473b3cee",
   "metadata": {},
   "source": [
    "### **Exploratory Data Analysis**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10155e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c81e44e",
   "metadata": {},
   "source": [
    "### **Hypothesis Testing**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eceaefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "820e27e6",
   "metadata": {},
   "source": [
    "### **Communication of insights attained**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3138a3-bc9c-4321-9da3-a480849d4e22",
   "metadata": {},
   "source": [
    "## Final Notes: Future Refinements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ea463f-0174-4b97-96e4-627ef1f1c1f8",
   "metadata": {},
   "source": [
    "If we were to continue to refine the project, there are several things we'd like to do to either meet goals had initially and did not complete, or refine the project to fix an error we realized later in the project would pose an issue. Some of these may be listed above, but are restated here to provide a concise and compact list for future use. \n",
    "\n",
    "### Incomplete Goals\n",
    "* include abstentions and absenses in the error calculation for each plot to more accurately represent the accuracy of each plot\n",
    "* do a frequency analysis on abstentions and absenses over time, so that we can determine which countries abstain or are absent the most, and later analyze any patterns we find\n",
    "\n",
    "### Errors\n",
    "* When determining which categories to use, we excluded all resolutions involving international peacekeeping, security, and weapons as most countries are likely to vote the same way and including this data may neutralize other data in some sense. However, some of the data we included in this category, and excluded from our dataset, are resolutions supporting or antagolizing certain countries in terms of war or international peackeeping situations, which may be relevant to our dataset and to our analysis. Although the resolution to this error is relatively simple, it would take several hours and the issue was found relatively late in the project cycle; we did not have enough time to execute the solution.\n",
    "* instead of manually determining the categories we wanted to use, it would be nice to somehow figure out which committees each resolution originated from and use those as deterministic factors. This method would be more consistent than relying on our own knowledge and research of each resolution. \n",
    "* in our code when reading in data, we assume that the file has already been created. To generalize this and make it accessible to anyone who wants to run this code from scratch, we would to make checks for this to see if the file has been created yet before reading it in. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd35ea6-882d-4d6e-9a79-60e580fcd5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
