{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bb0680",
   "metadata": {},
   "source": [
    "# United Nations Voting Patterns\n",
    "#### [CMSC320 Final Tutorial]\n",
    "Authors: Lauren Brown, Angel Lin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3157a-becc-4e0d-8a43-1568da875d0f",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "* get rid of requests we don't use\n",
    "* annotate the code to explain what we're doing and why [tutorial!]\n",
    "* have to explain what broad categories we wanted to analyze and why\n",
    "    * clean up our doc about what categories we want to use and add it to the github, explain why we are only using certain [un] categories for now (most bang for our buck)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffbd974",
   "metadata": {},
   "source": [
    "### **Introduction**\n",
    "* information about the UN\n",
    "    * History\n",
    "    * structure: general assembly, security Council, committees\n",
    "    * how voting works (yes, no, absentee, not present, not a nation) and what they could mean\n",
    "* why this information is important to look at\n",
    "* Question: As countries rise and fall, does UN voting show any patterns? Do voting blocks form and dissapate over time?\n",
    "    * we want to look for clusters in UN voting --> what does this say? are countries more likely to vote certain way on issues \n",
    "\n",
    "**Hypotheses**  \n",
    "Hypothesis: As countries rise and fall from power, clusters will form and disolve around those countries.  \n",
    "Null Hypothesis: There are no relations between country votes over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8af61b",
   "metadata": {},
   "source": [
    "### **Data Collection** \n",
    "* collected categories of resolutions\n",
    "* decided which to focus on/had relations --> development & human rights\n",
    "* sorted them manually\n",
    "* scraped resolution links and then voting data using requests, beautiful soup, etc\n",
    "* needed to use rate limiter because of unconfirmed scraping permissions\n",
    "* needed to save data collected to file incase anything was lost during long scraping session due to rate limiter (took approx. 3 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717d1d6d-d43c-4fc3-a3c6-1cb7ad1980ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff6755-13cf-4fe3-a739-e9e2878a589e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "category_links_df = pd.read_csv('category-links.csv')\n",
    "\n",
    "visited_categories = pd.read_csv('visited_cats.csv')['visited categories'].tolist()\n",
    "resolution_urls = pd.read_csv('res_urls.csv')['res_urls'].tolist()\n",
    "total_resolutions = 0\n",
    "\n",
    "category_links_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00ed82f4-298a-4860-aced-23a159ca6c3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_res_links_from_page(page_link):\n",
    "    \n",
    "    links = []\n",
    "    \n",
    "    page = requests.get(page_link)\n",
    "    if page.status_code != 200:\n",
    "        raise Exception(\"Something went wrong loading category: \" + category + \", error code: \" + page.status_code)\n",
    "\n",
    "    html = page.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    resolution_cnt = int(soup.find(\"strong\", {\"class\": None}).text)\n",
    "\n",
    "    if resolution_cnt > 50:\n",
    "        if resolution_cnt%50 == 0:\n",
    "            page_count = (int) (resolution_cnt/50)\n",
    "        else: page_count = int((resolution_cnt/50) + 1)\n",
    "    else: page_count = 1\n",
    "    \n",
    "    for page in range(page_count):\n",
    "\n",
    "        for div in soup.find_all(\"div\", {\"class\": \"moreinfo\"}):\n",
    "            res_link_suffix = div.find(\"a\")[\"href\"]\n",
    "            links.append('https://digitallibrary.un.org' + res_link_suffix)\n",
    "        \n",
    "        time.sleep(5)\n",
    "\n",
    "        #load the next page if you're not already on the last page (0 indexing)\n",
    "        if (page+1 != page_count):\n",
    "            next_page_link_suffix = soup.find(\"span\", {\"class\": \"rec-navigation\"}).findAll(\"a\")[-1][\"href\"]\n",
    "            next_page_link = 'https://digitallibrary.un.org' + next_page_link_suffix\n",
    "\n",
    "            page = requests.get(next_page_link)\n",
    "            if page.status_code != 200:\n",
    "                raise Exception(\"Something went wrong loading next page, error code: \" + page.status_code)\n",
    "\n",
    "            html = page.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "        \n",
    "    if (resolution_cnt != len(links)):\n",
    "        raise Exception(\"resolution count does not match\")\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff75b4b-df2c-46e2-99f0-329b00b6f545",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Make resolution_urls unique\n",
    "def unique(list1):\n",
    "    # initialize a null list\n",
    "    unique_list = []\n",
    "     \n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4fcd568-effa-4678-b05a-b04c711c8a23",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get the initial website with the categories\n",
    "for cat, link in zip (category_links_df[\"un category\"], category_links_df[\"link\"]):\n",
    "    if cat not in visited_categories:\n",
    "        try:\n",
    "            cat_res_links = get_res_links_from_page(link) #grab the links, may throw an exception\n",
    "            resolution_urls = resolution_urls + cat_res_links #append the new links list to the bigger old links list\n",
    "            visited_categories.append(cat)\n",
    "        except :\n",
    "            print(\"oh no the UN blocked you maybe :(\")\n",
    "        finally:\n",
    "            time.sleep(5) #delay to hopefully prevent the un from detecting and blocking us\n",
    "\n",
    "unq_res_urls = unique(resolution_urls)\n",
    "res_urls_df = pd.DataFrame(unq_res_urls, columns = ['res_urls'])\n",
    "res_urls_df.to_csv('res_urls.csv', index=False)\n",
    "visited_cats = pd.DataFrame(visited_categories, columns = ['visited categories'])\n",
    "visited_cats.to_csv('visited_cats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed536e1a-d28c-4924-a9d8-2ab86e77610c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for all voting data df, index column is the country and each following column is the resolution id. \n",
    "# cell is each country's vote (Y if yes, N if no, A if abstain, NP if not present, or NaN if the country didn't exist to vote at the time\n",
    "all_voting_data = pd.read_csv('all_voting_data.csv')\n",
    "\n",
    "## rows are resolution id's, columns are names of resolutions and years they were voted on\n",
    "all_res_data = pd.read_csv('all_res_data.csv')\n",
    "\n",
    "resolution_urls = pd.read_csv('res_urls.csv')['res_urls'].tolist()\n",
    "visited_res_urls = pd.read_csv('visited_res_urls.csv')['visited_res_urls'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092c5ef",
   "metadata": {},
   "source": [
    "### **Data Processing**  \n",
    "\n",
    "* stored data in 2 data frames\n",
    "* explain 2 df setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad9eddd6-ec75-4380-874b-1096b17792a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_resolution(res_url):\n",
    "    res_page = requests.get(res_url)\n",
    "    if res_page.status_code != 200:\n",
    "        raise Exception(\"Something went wrong loading resolution, error code: \" + res_page.status_code)\n",
    "    \n",
    "    html = res_page.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    metadata = soup.find(\"div\", {\"id\" : \"details-collapse\"})\n",
    "\n",
    "    #checking to make sure the vote was recorded\n",
    "    # we only care about recorded votes since they allow us to track how countries change their views over time\n",
    "    row_content_meta = metadata.find_all(\"span\", {\"class\" : \"value col-xs-12 col-sm-9 col-md-10\"})\n",
    "    recorded_vote = [False if 'NON-RECORDED' in row.get_text() else True for row in row_content_meta]\n",
    "\n",
    "    if False not in recorded_vote:\n",
    "\n",
    "        rows = metadata.find_all(\"div\", {\"class\" : \"metadata-row\"})\n",
    "\n",
    "        title = \"\"\n",
    "        res_id = \"\"\n",
    "        date = \"\"\n",
    "        vote_table = \"\"\n",
    "\n",
    "        for row in rows:\n",
    "            row_title = row.find(\"span\", {\"class\" : \"title col-xs-12 col-sm-3 col-md-2\"}).text\n",
    "            row_value = row.find(\"span\", {\"class\" : \"value col-xs-12 col-sm-9 col-md-10\"})\n",
    "\n",
    "            #strip newline chars from the string\n",
    "            row_title = row_title.strip()\n",
    "\n",
    "            #get the information we want from the html\n",
    "            if row_title == 'Title':\n",
    "                title = row_value.text\n",
    "            elif row_title == 'Resolution':\n",
    "                res_id = row_value.text\n",
    "            elif row_title == 'Vote date':\n",
    "                date = row_value.text\n",
    "                dt = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "            elif row_title == 'Vote':\n",
    "                vote_table = row_value\n",
    "\n",
    "        # some resolutions don't have the full date but the year exists elsewhere on the page, so extract that in those instances\n",
    "        if date == \"\":\n",
    "            year = soup.find(\"div\", {\"class\" : \"one-row-metadata value\"}).text.strip()\n",
    "            dt = datetime.strptime(year, \"%Y\")\n",
    "            \n",
    "        #get resolution metadata minus voting data, append it as a row to the df of all resolution metadata     \n",
    "        res_data = pd.DataFrame({'Resolution ID': [res_id],\n",
    "                        'Resolution Name' : [title],\n",
    "                        'Year' : [dt.year]})  \n",
    "\n",
    "        #get vote information into a dataframe \n",
    "        vts = str(vote_table)\n",
    "\n",
    "        for i in range(len(vts)):\n",
    "            if vts[i] in ['Y', 'N', 'A']:\n",
    "                vts = vts[:i]+'<br/> ' + vts[i:]\n",
    "                break\n",
    "            elif vts[i:i+2] == '> ': #if the first country in the list was absent and didn't vote, string should look like this\n",
    "                vts = vts[:i]+'<br/> ' + vts[i:]\n",
    "                break\n",
    "        \n",
    "        vts = vts.replace(\"<br>\", \"<br/>\")\n",
    "\n",
    "        #vts is a string but to parse it using beautifulsoup we want it as soup\n",
    "        vote_table = BeautifulSoup(vts, 'html.parser') \n",
    "        #print(str(vote_table))\n",
    "        \n",
    "        res_voting_data = pd.DataFrame(columns = ['country', res_id])\n",
    "        \n",
    "        for br in vote_table.findAll('br'):\n",
    "            next_s = br.nextSibling\n",
    "            \n",
    "            if next_s[0:2].strip() in ['Y', 'N', 'A']:\n",
    "                vote = next_s[0:2].strip()\n",
    "                country = next_s[3:].strip()\n",
    "            else:\n",
    "                vote = 'NP'\n",
    "                country = next_s.strip()\n",
    "\n",
    "            res_voting_data.loc[len(res_voting_data.index)] = [country, vote] \n",
    "\n",
    "        return (res_data, res_voting_data)\n",
    "    return (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91104853",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get vote data from each resolution\n",
    "\n",
    "#resolution df (x= resolution index, y = name, year)\n",
    "#country_votes df (row = country, col= resolution index) row,col = vote\n",
    "try:\n",
    "    for res_url in resolution_urls:\n",
    "        # print(res_url)\n",
    "        try:\n",
    "            if res_url not in visited_res_urls:\n",
    "                res_data, res_voting_data = process_resolution(res_url)\n",
    "                #print(res_data)\n",
    "                #print(res_voting_data)\n",
    "\n",
    "                #once you have the data for the resolution, add it to the larger dfs of all the data (voting and otherwise) \n",
    "                #for all resolutions\n",
    "                if (res_data, res_voting_data) is not (None, None):\n",
    "                    \n",
    "                    #add as a row to the end of the df\n",
    "                    all_res_data = pd.concat([all_res_data, res_data], ignore_index = True, axis = 0)\n",
    "                    \n",
    "                    #add as a column -> outer merge to make sure countries join correctly\n",
    "                    all_voting_data = all_voting_data.merge(res_voting_data, how='outer', on='country') \n",
    "\n",
    "                visited_res_urls.append(res_url)\n",
    "                time.sleep(5) \n",
    "        except:\n",
    "            print(\"error somewhere\")\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # save everything\n",
    "    all_res_data.to_csv('all_res_data.csv', index=False)\n",
    "    all_voting_data.to_csv('all_voting_data.csv', index=False)\n",
    "    \n",
    "    visited_res_url_df = pd.DataFrame(visited_res_urls, columns = ['visited_res_urls'])\n",
    "    visited_res_url_df.to_csv('visited_res_urls.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52f87a",
   "metadata": {},
   "source": [
    "### **Data Visualization/Representation**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2e3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "473b3cee",
   "metadata": {},
   "source": [
    "### **Exploratory Data Analysis**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10155e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c81e44e",
   "metadata": {},
   "source": [
    "### **Hypothesis Testing**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eceaefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "820e27e6",
   "metadata": {},
   "source": [
    "### **Communication of insights attained**  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
